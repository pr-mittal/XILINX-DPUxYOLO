{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Contest\n",
    "\n",
    "### Notebook\n",
    "Your notebook contains 4 code cells:\n",
    "\n",
    "1. Importing all libraries and creating your Team object.\n",
    "1. Downloading the overlay, and performany any one-time configuration.\n",
    "1. Python callback function and any other Python helper functions.\n",
    "1. Running object detection\n",
    "1. Cleanup\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Create Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/siliconmerc/git/dac_sdc_2023/.venv/bin/python3 -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../common\"))\n",
    "\n",
    "# import math\n",
    "# import time\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "# from matplotlib import pyplot\n",
    "# import cv2\n",
    "# from datetime import datetime\n",
    "import os\n",
    "# import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import colorsys\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import pynq\n",
    "from pynq_dpu import DpuOverlay\n",
    "import dac_sdc\n",
    "# from IPython.display import display\n",
    "\n",
    "team_name = 'Sapiens_Reconfigureable'\n",
    "dac_sdc.BATCH_SIZE = 2\n",
    "team = dac_sdc.Team(team_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your team directory where you can access your bitstream, notebook, and any other files you submit, is available as `team.team_dir`.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the overlay/bitstream and weight loading\n",
    "Overlay/bitstream loading must be executed in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitfile = team.get_bitstream_path()\n",
    "print(bitfile)\n",
    "# overlay = pynq.Overlay(bitfile)\n",
    "# dma = overlay.axi_dma_0\n",
    "overlay = DpuOverlay(bitfile)\n",
    "overlay.load_model(\"hw/yolov3_kv260.xmodel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python Callback Function and Helper Functions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing the picture through the pipeline\n",
    "In this example, we use contiguous memory arrays for sending and receiving data via DMA.\n",
    "\n",
    "The size of the buffer depends on the size of the input or output data.  The example images are 640x360 (same size as training and test data), and we will use `pynq.allocate` to allocate contiguous memory.\n",
    "\n",
    "### Callback function\n",
    "The callback function:\n",
    "  - Will be called on each batch of images (will be called many times)\n",
    "  - Is prvided with a list of tuples of (image path, RGB image)\n",
    "  - It should return a dictionary with an entry for each image:\n",
    "    - Key: Image name (`img_path.name`)\n",
    "    - Value: Dictionary of item type and bounding box (keys: `type`, `x`, `y`, `width`, `height`)\n",
    "\n",
    "See the code below for an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# anchor_list = [10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326]\n",
    "# anchor_float = [float(x) for x in anchor_list]\n",
    "# anchors = np.array(anchor_float).reshape(-1, 2)\n",
    "\n",
    "'''Get model classification information'''\t\n",
    "def get_class(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "    \n",
    "classes_path = \"../images/label.txt\"\n",
    "# os.path.is\n",
    "\n",
    "class_names = get_class(classes_path)\n",
    "\n",
    "# num_classes = len(class_names)\n",
    "# hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "# colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "# colors = list(map(lambda x: \n",
    "#                   (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), \n",
    "#                   colors))\n",
    "# random.seed(0)\n",
    "# random.shuffle(colors)\n",
    "# random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''resize image with unchanged aspect ratio using padding'''\n",
    "def letterbox_image(image, size):\n",
    "    ih, iw, _ = image.shape\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    #print(scale)\n",
    "    \n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "    #print(nw)\n",
    "    #print(nh)\n",
    "\n",
    "    image = cv2.resize(image, (nw,nh), interpolation=cv2.INTER_LINEAR)\n",
    "    new_image = np.ones((h,w,3), np.uint8) * 128\n",
    "    h_start = (h-nh)//2\n",
    "    w_start = (w-nw)//2\n",
    "    new_image[h_start:h_start+nh, w_start:w_start+nw, :] = image\n",
    "    return new_image\n",
    "\n",
    "\n",
    "'''image preprocessing'''\n",
    "def pre_process(image, model_image_size):\n",
    "    image = image[...,::-1]\n",
    "    image_h, image_w, _ = image.shape\n",
    " \n",
    "    if model_image_size != (None, None):\n",
    "        assert model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "        assert model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "        boxed_image = letterbox_image(image, tuple(reversed(model_image_size)))\n",
    "    else:\n",
    "        new_image_size = (image_w - (image_w % 32), image_h - (image_h % 32))\n",
    "        boxed_image = letterbox_image(image, new_image_size)\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0) \t\n",
    "    return image_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define a few functions to post-process the output after running a DPU task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_feats(feats, anchors, num_classes, input_shape):\n",
    "    num_anchors = len(anchors)\n",
    "    anchors_tensor = np.reshape(np.array(anchors, dtype=np.float32), [1, 1, 1, num_anchors, 2])\n",
    "    grid_size = np.shape(feats)[1:3]\n",
    "    nu = num_classes + 5\n",
    "    predictions = np.reshape(feats, [-1, grid_size[0], grid_size[1], num_anchors, nu])\n",
    "    grid_y = np.tile(np.reshape(np.arange(grid_size[0]), [-1, 1, 1, 1]), [1, grid_size[1], 1, 1])\n",
    "    grid_x = np.tile(np.reshape(np.arange(grid_size[1]), [1, -1, 1, 1]), [grid_size[0], 1, 1, 1])\n",
    "    grid = np.concatenate([grid_x, grid_y], axis = -1)\n",
    "    grid = np.array(grid, dtype=np.float32)\n",
    "\n",
    "    box_xy = (1/(1+np.exp(-predictions[..., :2])) + grid) / np.array(grid_size[::-1], dtype=np.float32)\n",
    "    box_wh = np.exp(predictions[..., 2:4]) * anchors_tensor / np.array(input_shape[::-1], dtype=np.float32)\n",
    "    box_confidence = 1/(1+np.exp(-predictions[..., 4:5]))\n",
    "    box_class_probs = 1/(1+np.exp(-predictions[..., 5:]))\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = np.array(input_shape, dtype = np.float32)\n",
    "    image_shape = np.array(image_shape, dtype = np.float32)\n",
    "    new_shape = np.around(image_shape * np.min(input_shape / image_shape))\n",
    "    offset = (input_shape - new_shape) / 2. / input_shape\n",
    "    scale = input_shape / new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes = np.concatenate([\n",
    "        box_mins[..., 0:1],\n",
    "        box_mins[..., 1:2],\n",
    "        box_maxes[..., 0:1],\n",
    "        box_maxes[..., 1:2]\n",
    "    ], axis = -1)\n",
    "    boxes *= np.concatenate([image_shape, image_shape], axis = -1)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def boxes_and_scores(feats, anchors, classes_num, input_shape, image_shape):\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = _get_feats(feats, anchors, classes_num, input_shape)\n",
    "    boxes = correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = np.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = np.reshape(box_scores, [-1, classes_num])\n",
    "    return boxes, box_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Draw detection frame'''\n",
    "def draw_bbox(image, bboxes, classes):\n",
    "    \"\"\"\n",
    "    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n",
    "    \"\"\"\n",
    "    num_classes = len(classes)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        fontScale = 0.5\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
    "        c1, c2 = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "        cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
    "    return image\n",
    "\n",
    "\n",
    "def nms_boxes(boxes, scores):\n",
    "    \"\"\"Suppress non-maximal boxes.\n",
    "\n",
    "    # Arguments\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "\n",
    "    # Returns\n",
    "        keep: ndarray, index of effective boxes.\n",
    "    \"\"\"\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2-x1+1)*(y2-y1+1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w1 = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h1 = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w1 * h1\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(ovr <= 0.55)[0]  # threshold\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, boxes, scores, classes):\n",
    "    _, ax = plt.subplots(1)\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image_h, image_w, _ = image.shape\n",
    "\n",
    "    for i, bbox in enumerate(boxes):\n",
    "        [top, left, bottom, right] = bbox\n",
    "        width, height = right - left, bottom - top\n",
    "        center_x, center_y = left + width*0.5, top + height*0.5\n",
    "        score, class_index = scores[i], classes[i]\n",
    "        label = '{}: {:.4f}'.format(class_names[class_index], score) \n",
    "        color = tuple([color/255 for color in colors[class_index]])\n",
    "        ax.add_patch(Rectangle((left, top), width, height,\n",
    "                               edgecolor=color, facecolor='none'))\n",
    "        ax.annotate(label, (center_x, center_y), color=color, weight='bold', \n",
    "                    fontsize=12, ha='center', va='center')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(yolo_outputs, image_shape, class_names, anchors):\n",
    "    score_thresh = 0.2\n",
    "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    input_shape = np.shape(yolo_outputs[0])[1 : 3]\n",
    "    input_shape = np.array(input_shape)*32\n",
    "\n",
    "    for i in range(len(yolo_outputs)):\n",
    "        _boxes, _box_scores = boxes_and_scores(\n",
    "            yolo_outputs[i], anchors[anchor_mask[i]], len(class_names), \n",
    "            input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = np.concatenate(boxes, axis = 0)\n",
    "    box_scores = np.concatenate(box_scores, axis = 0)\n",
    "\n",
    "    mask = box_scores >= score_thresh\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(len(class_names)):\n",
    "        class_boxes_np = boxes[mask[:, c]]\n",
    "        class_box_scores_np = box_scores[:, c]\n",
    "        class_box_scores_np = class_box_scores_np[mask[:, c]]\n",
    "        nms_index_np = nms_boxes(class_boxes_np, class_box_scores_np) \n",
    "        class_boxes_np = class_boxes_np[nms_index_np]\n",
    "        class_box_scores_np = class_box_scores_np[nms_index_np]\n",
    "        classes_np = np.ones_like(class_box_scores_np, dtype = np.int32) * c\n",
    "        boxes_.append(class_boxes_np)\n",
    "        scores_.append(class_box_scores_np)\n",
    "        classes_.append(classes_np)\n",
    "    boxes_ = np.concatenate(boxes_, axis = 0)\n",
    "    scores_ = np.concatenate(scores_, axis = 0)\n",
    "    classes_ = np.concatenate(classes_, axis = 0)\n",
    "\n",
    "    return boxes_, scores_, classes_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that our original images are not  640x640 so we need to preprocess them later to make sure it fits our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'img'\n",
    "original_images = sorted([i for i in os.listdir(image_folder) if i.endswith(\"JPEG\")])\n",
    "total_images = len(original_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we should be able to use VART to do image classification.\n",
    "dpu = overlay.runner\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "\n",
    "#values of out for 20 classes\n",
    "shapeOut0 = (tuple(outputTensors[0].dims)) # (1, 13, 13, 75)\n",
    "shapeOut1 = (tuple(outputTensors[1].dims)) # (1, 26, 26, 75)\n",
    "shapeOut2 = (tuple(outputTensors[2].dims)) # (1, 52, 52, 75)\n",
    "\n",
    "outputSize0 = int(outputTensors[0].get_data_size() / shapeIn[0]) # 12675\n",
    "outputSize1 = int(outputTensors[1].get_data_size() / shapeIn[0]) # 50700\n",
    "outputSize2 = int(outputTensors[2].get_data_size() / shapeIn[0]) # 202800\n",
    "\n",
    "# We can define a few buffers to store input and output data. They will be reused during multiple runs.\n",
    "\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "output_data = [np.empty(shapeOut0, dtype=np.float32, order=\"C\"), \n",
    "               np.empty(shapeOut1, dtype=np.float32, order=\"C\"),\n",
    "               np.empty(shapeOut2, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_callback(rgb_imgs, display=False):\n",
    "    # [my_callback(i) for i in range(total_images)]\n",
    "    object_locations_by_image = {}\n",
    "    for (img_path, img) in rgb_imgs:\n",
    "        # Pre-processing\n",
    "        input_image=img\n",
    "        image_size = input_image.shape[:2]\n",
    "        image_data = np.array(pre_process(input_image, (640, 640)), dtype=np.float32)\n",
    "        \n",
    "        # Fetch data to DPU and trigger it\n",
    "        image[0,...] = image_data.reshape(shapeIn[1:])\n",
    "        job_id = dpu.execute_async(input_data, output_data)\n",
    "        dpu.wait(job_id)\n",
    "        \n",
    "        # Retrieve output data\n",
    "        conv_out0 = np.reshape(output_data[0], shapeOut0)\n",
    "        conv_out1 = np.reshape(output_data[1], shapeOut1)\n",
    "        conv_out2 = np.reshape(output_data[2], shapeOut2)\n",
    "        yolo_outputs = [conv_out0, conv_out1, conv_out2]\n",
    "        \n",
    "        # Decode output from YOLOv3\n",
    "        boxes, scores, classes = evaluate(yolo_outputs, image_size, class_names, anchors)\n",
    "        \n",
    "        if display:\n",
    "            _ = draw_boxes(input_image, boxes, scores, classes)\n",
    "        print(\"Number of detected objects: {}\".format(len(boxes)))\n",
    "        # Save to dictionary by image filename\n",
    "        object_locations_by_image[img_path.name] = boxes        \n",
    "    return object_locations_by_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Object Detection\n",
    "\n",
    "Call the following function to run the object detection.  Extra debug output is enabled when `debug` is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team.run(my_callback, debug=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to free the contiguous memory after usage.\n",
    "# del in_buffer\n",
    "# del out_buffer\n",
    "del overlay\n",
    "del dpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
